{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necesarias\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "yj7kF9J45hzK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bPxjobg15Hsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989c556f-68a5-4052-e0ac-ba4e3ae9fcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo 'text_dataset.csv' creado con éxito.\n"
          ]
        }
      ],
      "source": [
        "# Crear un conjunto de datos sintético y guardarlo como CSV\n",
        "# Ejemplos de texto y etiquetas\n",
        "data = {\n",
        "    \"texto\": [\n",
        "        \"Me gusta el fútbol\",\n",
        "        \"El clima es hermoso hoy\",\n",
        "        \"No me gusta la lluvia\",\n",
        "        \"El café es delicioso\",\n",
        "        \"Prefiero té que café\",\n",
        "        \"La comida argentina es increíble\",\n",
        "        \"Amo la música\",\n",
        "        \"Los días soleados son los mejores\",\n",
        "        \"La lectura es un buen pasatiempo\",\n",
        "        \"Me gusta aprender cosas nuevas\",\n",
        "        \"No me gusta caminar bajo el sol\",\n",
        "        \"La playa estaba limpia, pero el día estaba frio\",\n",
        "        \"La comida estaba rica, pero fria\",\n",
        "    ],\n",
        "    \"etiquetas\": [\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        0,  # Negativa\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        0,  # Negativa\n",
        "        0,  # Negativa\n",
        "        0,  # Negativa\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convertir a DataFrame\n",
        "datos = pd.DataFrame(data)\n",
        "\n",
        "# Guardar como CSV\n",
        "datos.to_csv(\"text_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Archivo 'text_dataset.csv' creado con éxito.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos de texto\n",
        "datos = pd.read_csv(\"text_dataset.csv\")"
      ],
      "metadata": {
        "id": "WwvHF_Nm5tWe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenización del texto\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(datos[\"texto\"])\n",
        "secuencias = tokenizer.texts_to_sequences(datos[\"texto\"])\n",
        "maxlen = 10  # Longitud máxima de las secuencias\n",
        "X = pad_sequences(secuencias, maxlen=maxlen)\n",
        "y = datos[\"etiquetas\"].values"
      ],
      "metadata": {
        "id": "wTZ7P-b85zbE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiar el modelo a uno adecuado para texto\n",
        "modelo = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=64, input_length=maxlen),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')  # Cambiar según el caso de uso\n",
        "])"
      ],
      "metadata": {
        "id": "Lx3iMaBf51X_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23bb82f4-8e87-422b-dadb-de376c8f5865"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilación del modelo\n",
        "modelo.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "O7UihT4C53Pi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "entrenamiento = modelo.fit(X, y, epochs=15, batch_size=2)"
      ],
      "metadata": {
        "id": "xbd0twWW5404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d002e78f-bbb9-4b90-bd90-f903e5a4caea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9511 - loss: 0.6825\n",
            "Epoch 2/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5975 - loss: 0.6739\n",
            "Epoch 3/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7402 - loss: 0.6573\n",
            "Epoch 4/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6256 - loss: 0.6467     \n",
            "Epoch 5/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8725 - loss: 0.5985\n",
            "Epoch 6/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7663 - loss: 0.5939\n",
            "Epoch 7/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6881 - loss: 0.6036 \n",
            "Epoch 8/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7506 - loss: 0.5693 \n",
            "Epoch 9/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6392 - loss: 0.5973\n",
            "Epoch 10/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8423 - loss: 0.4927\n",
            "Epoch 11/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7506 - loss: 0.5292\n",
            "Epoch 12/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8340 - loss: 0.4613\n",
            "Epoch 13/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7902 - loss: 0.4883\n",
            "Epoch 14/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8423 - loss: 0.4315\n",
            "Epoch 15/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7850 - loss: 0.4421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción con ejemplo de texto\n",
        "texto_ejemplo = \"El café es delicioso, pero estaba frio\"\n",
        "secuencia_ejemplo = tokenizer.texts_to_sequences([texto_ejemplo])\n",
        "secuencia_ejemplo = pad_sequences(secuencia_ejemplo, maxlen=maxlen)\n",
        "prediccion = modelo.predict(secuencia_ejemplo)\n",
        "print(f\"Predicción para el texto '{texto_ejemplo}': {prediccion[0]}\")"
      ],
      "metadata": {
        "id": "5FuKBr-u5xs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd2a36b-5c1d-4c0b-e959-7052500d4d23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "Predicción para el texto 'El café es delicioso, pero estaba frio': [0.6352287]\n"
          ]
        }
      ]
    }
  ]
}