{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Análisis de Sentimiento con una Red LSTM usando Keras\n",
        "##🎯 Objetivo\n",
        "En esta actividad vas a construir un modelo de red neuronal recurrente (RNN), específicamente una LSTM, usando la API Keras de TensorFlow. El modelo leerá frases en español y clasificará su sentimiento como positivo o negativo.\n",
        "\n"
      ],
      "metadata": {
        "id": "qSvHGspZdXSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🧰 1. Preparación del entorno\n",
        "Importamos las librerías necesarias. Si estás en Google Colab, podés ejecutar la celda tal como está."
      ],
      "metadata": {
        "id": "cy_gLJYldf5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "R4KyRLqWdfn3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🗂️ 2. Datos de entrenamiento\n",
        "Vamos a usar las mismas frases que en la actividad anterior, pero ahora procesadas como secuencias de palabras, no como bolsa de palabras."
      ],
      "metadata": {
        "id": "UpJwnXPUdtbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KV8jghGzdSRj"
      },
      "outputs": [],
      "source": [
        "frases = [\n",
        "    \"La verdad, este lugar está bárbaro. Muy recomendable\",\n",
        "    \"Una porquería de servicio, nunca más vuelvo\",\n",
        "    \"Me encantó la comida, aunque la música estaba muy fuerte\",\n",
        "    \"El envío fue lento y el producto llegó dañado. Qué desastre\",\n",
        "    \"Todo excelente. Atención de diez\",\n",
        "    \"Qué estafa, me arrepiento de haber comprado\",\n",
        "    \"Muy conforme con el resultado final\",\n",
        "    \"No me gustó para nada la experiencia\",\n",
        "    \"Superó mis expectativas, ¡gracias!\",\n",
        "    \"No lo recomiendo, mala calidad\"\n",
        "]\n",
        "\n",
        "etiquetas = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##✏️ 3. Tokenización y vectorización\n",
        "Con Keras, vamos a convertir las frases en secuencias de números, donde cada número representa una palabra del vocabulario."
      ],
      "metadata": {
        "id": "fJ-RfP1kd3zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenización\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(frases)\n",
        "\n",
        "# Secuencias numéricas\n",
        "secuencias = tokenizer.texts_to_sequences(frases)\n",
        "\n",
        "# Padding para que todas las frases tengan la misma longitud\n",
        "maxlen = max(len(seq) for seq in secuencias)\n",
        "X = pad_sequences(secuencias, maxlen=maxlen, padding='post')\n",
        "\n",
        "# Convertimos las etiquetas\n",
        "y = np.array(etiquetas)"
      ],
      "metadata": {
        "id": "IdBIn62nd3gA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🧱 4. Definición del modelo LSTM\n",
        "Vamos a usar una red con:\n",
        "\n",
        "* Capa de embedding (representación vectorial aprendida de cada palabra).\n",
        "\n",
        "* Una capa LSTM para captar la secuencia.\n",
        "\n",
        "* Una capa densa para clasificar."
      ],
      "metadata": {
        "id": "FfARMHgkeCUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 por el token OOV\n",
        "embedding_dim = 16\n",
        "lstm_units = 32\n",
        "\n",
        "# Modelo\n",
        "modelo = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n",
        "    LSTM(units=lstm_units),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "modelo.summary()"
      ],
      "metadata": {
        "id": "qdBFUXe_eCsg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "f9a73c27-2897-4847-dbac-cce42ed2bad5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🚀 5. Entrenamiento\n",
        "Entrenamos el modelo por unas pocas épocas para ver resultados rápidos en clase. Si tenés más tiempo o más datos, podés aumentarlas."
      ],
      "metadata": {
        "id": "M3TtQP9lePlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.fit(X, y, epochs=20, batch_size=2, verbose=1)\n"
      ],
      "metadata": {
        "id": "IO9WfKXEePS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4eaa758-0e20-4647-94e9-9ac42e22b5a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4389 - loss: 0.6941\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3806 - loss: 0.6954    \n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7069 - loss: 0.6910\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6361 - loss: 0.6909\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.6875 \n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9458 - loss: 0.6845\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7931 - loss: 0.6833\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9181 - loss: 0.6773\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8764 - loss: 0.6648\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.6495\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.6097\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.5511\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.4118\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.2806\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1578\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0833\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0508\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0431\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0362\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0260 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b5b3023d0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🧪 6. Evaluación con frases nuevas\n",
        "Ahora vamos a probar el modelo con frases no vistas y observar sus predicciones."
      ],
      "metadata": {
        "id": "KpqlBI4ReZv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frases_nuevas = [\n",
        "    \"Muy buena atención, quedé encantado\",\n",
        "    \"Horrible experiencia, no vuelvo más\",\n",
        "    \"Todo excelente, gracias por la atención\",\n",
        "    \"Me arrepiento completamente, fue un desastre\",\n",
        "    \"Un servicio impecable y rápido\"\n",
        "]\n",
        "\n",
        "# Tokenizamos y convertimos\n",
        "secuencias_nuevas = tokenizer.texts_to_sequences(frases_nuevas)\n",
        "X_nuevo = pad_sequences(secuencias_nuevas, maxlen=maxlen, padding='post')\n",
        "\n",
        "# Predicción\n",
        "predicciones = modelo.predict(X_nuevo)\n",
        "\n",
        "# Mostrar resultados\n",
        "for frase, pred in zip(frases_nuevas, predicciones):\n",
        "    clase = \"Positivo\" if pred[0] >= 0.5 else \"Negativo\"\n",
        "    print(f\"Frase: '{frase}' => Sentimiento predicho: {clase} ({pred[0]:.2f})\")\n"
      ],
      "metadata": {
        "id": "Bq7pY6EUeZd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dda60c8-e93f-4af5-afe1-2f60527a9cb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\n",
            "Frase: 'Muy buena atención, quedé encantado' => Sentimiento predicho: Positivo (0.97)\n",
            "Frase: 'Horrible experiencia, no vuelvo más' => Sentimiento predicho: Negativo (0.02)\n",
            "Frase: 'Todo excelente, gracias por la atención' => Sentimiento predicho: Positivo (0.97)\n",
            "Frase: 'Me arrepiento completamente, fue un desastre' => Sentimiento predicho: Negativo (0.02)\n",
            "Frase: 'Un servicio impecable y rápido' => Sentimiento predicho: Negativo (0.07)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🧠 Reflexión final\n",
        "##👉 ¿Qué aprendimos?\n",
        "\n",
        "* Cómo representar texto como secuencia de palabras usando Keras.\n",
        "\n",
        "* Qué es una red LSTM y cómo recuerda el contexto.\n",
        "\n",
        "* Cómo el orden de las palabras sí influye en el resultado.\n",
        "\n",
        "* Que las redes recurrentes pueden manejar frases más complejas que los MLP o perceptrones."
      ],
      "metadata": {
        "id": "TfghBPJPel0Y"
      }
    }
  ]
}