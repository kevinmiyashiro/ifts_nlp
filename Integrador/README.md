# Análisis de texto con spaCy y web scraping

Este Colab demuestra cómo extraer texto de una página web (web scraping) utilizando `requests` y `BeautifulSoup`, y luego procesarlo con `spaCy`, una biblioteca de Procesamiento del Lenguaje Natural (PNL).

**Técnicas utilizadas:**

- Extracción de texto de HTML
- Tokenización con spaCy
- Identificación de oraciones, palabras y entidades
- Lematización
- Etiquetado gramatical
- Visualización de dependencias
- Extracción de entidades nombradas
- Nube de palabras

**Flujo de trabajo:**

1. Se extrae el contenido de una página web utilizando `requests` y `BeautifulSoup`.
2. Se procesa el texto con `spaCy` para realizar tokenización, lematización, etiquetado gramatical, etc.
3. Se visualizan las dependencias sintácticas y las entidades nombradas.
4. Se crea una nube de palabras para visualizar la frecuencia de las palabras en el texto.


**Bibliotecas utilizadas:**

- `requests`
- `BeautifulSoup`
- `spaCy`
- `es_core_news_lg`
- `wordcloud`
- `matplotlib`
- `PIL`
- `nltk`

**Ejemplo:**

El Colab utiliza la página de Wikipedia de Lionel Messi como ejemplo para demostrar las técnicas de web scraping y PNL.


**Cómo usar este Colab:**

1. Ejecuta todas las celdas del Colab.
2. Observa los resultados del análisis de texto.
3. Modifica el código para analizar otras páginas web o textos.


**Recursos adicionales:**

- [Documentación de spaCy](https://spacy.io/usage/spacy-101)
- [Documentación de BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Documentación de NLTK](https://www.nltk.org/)



**Nota:** Este Colab está en español.

