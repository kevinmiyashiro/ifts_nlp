{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# Reconocimiento de Entidades Nombradas\n",
        "## Ejercicio Pr√°ctico - Procesamiento de Lenguaje Natural\n",
        "\n",
        "**Objetivos de Aprendizaje:**\n",
        "1. Implementar NER usando modelos pre-entrenados en espa√±ol\n",
        "2. Crear interfaces interactivas con Gradio\n",
        "3. Comparar enfoques: Transformers vs API Gemini\n",
        "4. Desarrollar prototipos r√°pidos para aplicaciones de PLN\n",
        "\n",
        "---\n",
        "**Entorno recomendado:** Google Colab o Amazon SageMaker Studio\n",
        "\n",
        "**Tiempo estimado:** 60-90 minutos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## Instalaci√≥n de Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Instalaci√≥n de librer√≠as necesarias\n",
        "%%capture\n",
        "!pip install -q transformers torch gradio google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar instalaci√≥n\n",
        "import sys\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(\"Todas las dependencias instaladas correctamente\")"
      ],
      "metadata": {
        "id": "cJksfScFfyjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_section"
      },
      "source": [
        "## Configuraci√≥n de APIs\n",
        "\n",
        "### Para Google Colab:\n",
        "1. And√° a la barra lateral izquierda y hac√© clic en üîë (Secrets)\n",
        "2. Agrega una nueva clave: `GOOGLE_API_KEY`\n",
        "3. Pega tu API key de Google AI Studio\n",
        "\n",
        "### Para SageMaker Studio:\n",
        "1. Configura las variables de entorno en tu instancia\n",
        "2. O usa el m√©todo de input manual m√°s abajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config_api"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuraci√≥n de API Key para Gemini\n",
        "try:\n",
        "    # M√©todo 1: Google Colab Secrets\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"API Key cargada desde Google Colab Secrets\")\n",
        "except:\n",
        "    # M√©todo 2: Variables de entorno (SageMaker)\n",
        "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
        "    if GOOGLE_API_KEY:\n",
        "        print(\"API Key cargada desde variables de entorno\")\n",
        "    else:\n",
        "        print(\"No se encontr√≥ GOOGLE_API_KEY\")\n",
        "        print(\"Podes continuar solo con la parte de Transformers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1_header"
      },
      "source": [
        "---\n",
        "# PARTE 1: NER con Transformers de Hugging Face\n",
        "\n",
        "Utilizaremos un modelo especializado en espa√±ol que puede identificar:\n",
        "- **PER**: Personas\n",
        "- **LOC**: Lugares\n",
        "- **ORG**: Organizaciones  \n",
        "- **MISC**: Miscel√°neo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_transformer_model"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Verificar disponibilidad de GPU\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "print(f\"üñ•Ô∏è  Dispositivo: {'GPU' if device == 0 else 'CPU'}\")\n",
        "\n",
        "# Cargar modelo de NER en espa√±ol\n",
        "print(\"üì• Cargando modelo de NER para espa√±ol...\")\n",
        "MODEL_NAME = \"mrm8488/bert-spanish-cased-finetuned-ner\"\n",
        "\n",
        "try:\n",
        "    ner_pipeline = pipeline(\n",
        "        \"ner\",\n",
        "        model=MODEL_NAME,\n",
        "        aggregation_strategy=\"simple\",\n",
        "        device=device\n",
        "    )\n",
        "    print(f\"Modelo {MODEL_NAME} cargado exitosamente\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error al cargar modelo: {e}\")\n",
        "    ner_pipeline = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_transformer_ner"
      },
      "outputs": [],
      "source": [
        "# Texto de ejemplo con contexto argentino\n",
        "texto_ejemplo = \"\"\"\n",
        "Hola, soy Mar√≠a Gonz√°lez y trabajo en la Universidad de Buenos Aires.\n",
        "Vivo en el barrio de San Telmo y mi empresa favorita es MercadoLibre.\n",
        "La semana pasada visit√© el Obelisco con mi amigo Carlos P√©rez,\n",
        "quien trabaja en Google Argentina. Nos encontramos en la estaci√≥n\n",
        "Constituci√≥n del subte y fuimos a comer un asado en La Boca.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analizar_entidades_transformers(texto):\n",
        "    \"\"\"Procesa texto y extrae entidades usando Transformers\"\"\"\n",
        "    if not ner_pipeline:\n",
        "        return []\n",
        "\n",
        "    entidades = ner_pipeline(texto)\n",
        "\n",
        "    # Formatear resultados\n",
        "    resultados = []\n",
        "    for ent in entidades:\n",
        "        resultados.append({\n",
        "            'texto': ent['word'],\n",
        "            'etiqueta': ent['entity_group'],\n",
        "            'confianza': round(ent['score'], 3),\n",
        "            'posicion': (ent['start'], ent['end'])\n",
        "        })\n",
        "\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "v40sR-IKYXyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probar el modelo\n",
        "print(\"üîç Analizando texto de ejemplo...\")\n",
        "print(f\"üìù Texto: {texto_ejemplo.strip()}\")\n",
        "print(\"\\nüìä Entidades encontradas:\")\n",
        "\n",
        "entidades_encontradas = analizar_entidades_transformers(texto_ejemplo)\n",
        "for ent in entidades_encontradas:\n",
        "    print(f\"  ‚Ä¢ {ent['texto']} ‚Üí {ent['etiqueta']} (confianza: {ent['confianza']})\")"
      ],
      "metadata": {
        "id": "lh7rDIQjYXtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2_header"
      },
      "source": [
        "---\n",
        "# PARTE 2: NER con API de Gemini\n",
        "\n",
        "Utilizaremos la API de Gemini para un an√°lisis m√°s detallado y contextual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_gemini"
      },
      "outputs": [],
      "source": [
        "# Configurar cliente Gemini\n",
        "cliente_gemini = None\n",
        "\n",
        "if GOOGLE_API_KEY:\n",
        "    try:\n",
        "        from google import genai\n",
        "        cliente_gemini = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "        print(\"Cliente Gemini configurado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al configurar Gemini: {e}\")\n",
        "else:\n",
        "    print(\"API Key de Gemini no disponible\")\n",
        "    print(\"Podes obtener una gratis en: https://ai.google.dev/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_gemini_ner"
      },
      "outputs": [],
      "source": [
        "def analizar_entidades_gemini(texto):\n",
        "    \"\"\"Analiza entidades usando Gemini API\"\"\"\n",
        "    if not cliente_gemini:\n",
        "        return \"‚ùå Cliente Gemini no disponible\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Extra√© todas las entidades nombradas del siguiente texto en espa√±ol argentino y clasific√°las:\n",
        "\n",
        "    CATEGOR√çAS:\n",
        "    - PERSONA: Nombres de personas\n",
        "    - LUGAR: Ciudades, pa√≠ses, barrios, direcciones, lugares espec√≠ficos\n",
        "    - ORGANIZACI√ìN: Empresas, universidades, instituciones\n",
        "    - MISCEL√ÅNEO: Otros nombres propios (productos, eventos, marcas)\n",
        "\n",
        "    FORMATO DE RESPUESTA:\n",
        "    [ENTIDAD] ‚Üí [CATEGOR√çA] ‚Üí [BREVE EXPLICACI√ìN]\n",
        "\n",
        "    TEXTO A ANALIZAR:\n",
        "    {texto}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        respuesta = cliente_gemini.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            contents=[prompt]\n",
        "        )\n",
        "        return respuesta.text\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {e}\"\n",
        "\n",
        "# Probar Gemini si est√° disponible\n",
        "if cliente_gemini:\n",
        "    print(\"üîç Analizando con Gemini...\")\n",
        "    resultado_gemini = analizar_entidades_gemini(texto_ejemplo)\n",
        "    print(\"\\nAn√°lisis de Gemini:\")\n",
        "    print(resultado_gemini)\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Saltando an√°lisis con Gemini (API Key no disponible)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3_header"
      },
      "source": [
        "---\n",
        "# PARTE 3: Interfaces Interactivas con Gradio\n",
        "\n",
        "Crearemos interfaces web interactivas para probar nuestros modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gradio_transformers"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def interfaz_ner_transformers(texto):\n",
        "    \"\"\"Interfaz para el modelo de Transformers\"\"\"\n",
        "    if not texto.strip():\n",
        "        return {\"text\": \"Ingresa un texto para analizar\", \"entities\": []}\n",
        "\n",
        "    if not ner_pipeline:\n",
        "        return {\"text\": \"Modelo no disponible\", \"entities\": []}\n",
        "\n",
        "    # Procesar con Transformers\n",
        "    entidades = ner_pipeline(texto)\n",
        "\n",
        "    # Formatear para Gradio HighlightedText\n",
        "    entidades_gradio = []\n",
        "    for ent in entidades:\n",
        "        entidades_gradio.append({\n",
        "            \"entity\": ent[\"entity_group\"],\n",
        "            \"word\": ent[\"word\"],\n",
        "            \"start\": ent[\"start\"],\n",
        "            \"end\": ent[\"end\"],\n",
        "            \"score\": ent[\"score\"]\n",
        "        })\n",
        "\n",
        "    return {\"text\": texto, \"entities\": entidades_gradio}\n",
        "\n",
        "# Ejemplos para la interfaz\n",
        "ejemplos_arg = [\n",
        "    \"Me llamo Juan P√©rez y trabajo en el Banco Naci√≥n en Buenos Aires.\",\n",
        "    \"Cristina Kirchner fue presidenta de Argentina y vive en Santa Cruz.\",\n",
        "    \"River Plate jugar√° contra Boca Juniors en el estadio Monumental.\",\n",
        "    \"Lionel Messi naci√≥ en Rosario y jug√≥ en el Barcelona.\",\n",
        "    \"La Universidad de La Plata es muy prestigiosa en Argentina.\"\n",
        "]\n",
        "\n",
        "# Crear interfaz\n",
        "demo_transformers = gr.Interface(\n",
        "    fn=interfaz_ner_transformers,\n",
        "    inputs=[\n",
        "        gr.Textbox(\n",
        "            label=\"üìù Texto a analizar\",\n",
        "            placeholder=\"Escribe aqu√≠ tu texto en espa√±ol...\",\n",
        "            lines=4\n",
        "        )\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.HighlightedText(\n",
        "            label=\"üéØ Entidades Identificadas\",\n",
        "            show_legend=True\n",
        "        )\n",
        "    ],\n",
        "    title=\"NER con Transformers - Espa√±ol (de argentina)\",\n",
        "    description=\"\"\"\n",
        "    **Modelo:** `mrm8488/bert-spanish-cased-finetuned-ner`\n",
        "\n",
        "    Identifica entidades nombradas en textos en espa√±ol:\n",
        "    - üßë **PER**: Personas\n",
        "    - üåç **LOC**: Lugares\n",
        "    - üè¢ **ORG**: Organizaciones\n",
        "    - üì¶ **MISC**: Miscel√°neo\n",
        "    \"\"\",\n",
        "    examples=ejemplos_arg,\n",
        "    allow_flagging=\"never\",\n",
        "    theme=gr.themes.Soft()\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Interfaz de Transformers creada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gradio_gemini"
      },
      "outputs": [],
      "source": [
        "# Interfaz para Gemini (solo si est√° disponible)\n",
        "if cliente_gemini:\n",
        "    def interfaz_ner_gemini(texto):\n",
        "        \"\"\"Interfaz para Gemini API\"\"\"\n",
        "        if not texto.strip():\n",
        "            return \"Ingresa un texto para analizar\"\n",
        "        return analizar_entidades_gemini(texto)\n",
        "\n",
        "    demo_gemini = gr.Interface(\n",
        "        fn=interfaz_ner_gemini,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üìù Texto a analizar\",\n",
        "                placeholder=\"Escribe aqu√≠ tu texto en espa√±ol...\",\n",
        "                lines=4\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üß† An√°lisis de Gemini\",\n",
        "                lines=10\n",
        "            )\n",
        "        ],\n",
        "        title=\"NER con Gemini - An√°lisis Detallado\",\n",
        "        description=\"\"\"\n",
        "        **Modelo:** Google Gemini 2.0 Flash\n",
        "\n",
        "        An√°lisis avanzado de entidades nombradas con explicaciones contextuales\n",
        "        optimizado para espa√±ol argentino.\n",
        "        \"\"\",\n",
        "        examples=ejemplos_arg,\n",
        "        allow_flagging=\"never\",\n",
        "        theme=gr.themes.Soft()\n",
        "    )\n",
        "    print(\"‚úÖ Interfaz de Gemini creada\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Interfaz de Gemini no creada (API Key no disponible)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gradio_comparison"
      },
      "outputs": [],
      "source": [
        "# Interfaz comparativa (solo si ambos est√°n disponibles)\n",
        "if ner_pipeline and cliente_gemini:\n",
        "    def comparar_modelos(texto):\n",
        "        \"\"\"Compara resultados de ambos modelos\"\"\"\n",
        "        if not texto.strip():\n",
        "            return \"Ingresa texto para comparar\", \"Ingresa texto para comparar\"\n",
        "\n",
        "        # Resultado Transformers\n",
        "        entidades_tf = analizar_entidades_transformers(texto)\n",
        "        resultado_tf = \"TRANSFORMERS:\\n\\n\"\n",
        "        for ent in entidades_tf:\n",
        "            resultado_tf += f\"‚Ä¢ {ent['texto']} ‚Üí {ent['etiqueta']} (confianza: {ent['confianza']})\\n\"\n",
        "\n",
        "        # Resultado Gemini\n",
        "        resultado_gemini = \"GEMINI:\\n\\n\" + analizar_entidades_gemini(texto)\n",
        "\n",
        "        return resultado_tf, resultado_gemini\n",
        "\n",
        "    demo_comparativo = gr.Interface(\n",
        "        fn=comparar_modelos,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üìù Texto a comparar\",\n",
        "                placeholder=\"Ingresa texto para ver la comparaci√≥n...\",\n",
        "                lines=3\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(label=\"Transformers\", lines=8),\n",
        "            gr.Textbox(label=\"Gemini\", lines=8)\n",
        "        ],\n",
        "        title=\"‚öîÔ∏è Comparaci√≥n: Transformers vs Gemini\",\n",
        "        description=\"Compara los resultados de ambos enfoques lado a lado.\",\n",
        "        examples=[\n",
        "            \"Diego Maradona jug√≥ en Boca Juniors y en el Napoli de Italia.\",\n",
        "            \"El gobierno argentino anunci√≥ medidas desde Casa Rosada.\"\n",
        "        ],\n",
        "        allow_flagging=\"never\"\n",
        "    )\n",
        "    print(\"‚úÖ Interfaz comparativa creada\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Interfaz comparativa no creada (requiere ambos modelos)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "launch_section"
      },
      "source": [
        "## üöÄ Lanzar Interfaces\n",
        "\n",
        "Ejecuta las celdas siguientes para lanzar las interfaces interactivas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch_transformers"
      },
      "outputs": [],
      "source": [
        "# Lanzar interfaz de Transformers\n",
        "if ner_pipeline:\n",
        "    print(\"üöÄ Lanzando interfaz de Transformers...\")\n",
        "    demo_transformers.launch(share=True, height=600)\n",
        "else:\n",
        "    print(\"‚ùå No se puede lanzar: modelo de Transformers no disponible\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch_gemini"
      },
      "outputs": [],
      "source": [
        "# Lanzar interfaz de Gemini\n",
        "if cliente_gemini:\n",
        "    print(\"üöÄ Lanzando interfaz de Gemini...\")\n",
        "    demo_gemini.launch(share=True, height=600)\n",
        "else:\n",
        "    print(\"‚ùå No se puede lanzar: API de Gemini no disponible\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch_comparison"
      },
      "outputs": [],
      "source": [
        "# Lanzar interfaz comparativa\n",
        "if ner_pipeline and cliente_gemini:\n",
        "    print(\"üöÄ Lanzando interfaz comparativa...\")\n",
        "    demo_comparativo.launch(share=True, height=600)\n",
        "else:\n",
        "    print(\"‚ùå No se puede lanzar: requiere ambos modelos disponibles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercises_section"
      },
      "source": [
        "---\n",
        "# üéì EJERCICIOS\n",
        "\n",
        "## üìù Ejercicio 1: Personalizaci√≥n (B√ÅSICO)\n",
        "1. Modifica los ejemplos para incluir m√°s contexto argentino espec√≠fico\n",
        "2. Agrega 3 ejemplos nuevos con nombres de barrios porte√±os\n",
        "3. Prob√° con texto de diferentes regiones de Argentina\n",
        "\n",
        "## üîß Ejercicio 2: An√°lisis Comparativo (INTERMEDIO)\n",
        "1. Crea una funci√≥n que cuente cu√°ntas entidades encuentra cada modelo\n",
        "2. Implementa un sistema de m√©tricas de tiempo de procesamiento\n",
        "3. Analiza en qu√© casos cada modelo funciona mejor\n",
        "\n",
        "## üöÄ Ejercicio 3: Extensiones Avanzadas (AVANZADO)\n",
        "1. Implementa procesamiento en lote de m√∫ltiples textos\n",
        "2. Crea una funci√≥n de exportaci√≥n de resultados a CSV\n",
        "3. Desarrolla un sistema de filtrado por tipo de entidad\n",
        "\n",
        "## üí° Proyecto Integrador\n",
        "Eleg√≠ una de estas aplicaciones y desarr√≥llala:\n",
        "- **Analizador de noticias argentinas**: Extrae personas y lugares de art√≠culos\n",
        "- **Procesador de CVs**: Identifica nombres, empresas y universidades\n",
        "- **An√°lisis de redes sociales**: Detecta menciones de pol√≠ticos y lugares\n",
        "\n",
        "## ü§î Preguntas de Reflexi√≥n\n",
        "1. ¬øCu√°les son las ventajas y desventajas de cada enfoque?\n",
        "2. ¬øEn qu√© casos usar√≠as un modelo local vs una API?\n",
        "3. ¬øC√≥mo evaluar√≠as la precisi√≥n de los resultados?\n",
        "4. ¬øQu√© consideraciones √©ticas debemos tener en cuenta?\n",
        "5. ¬øC√≥mo escalar√≠as esta soluci√≥n para procesar miles de documentos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_template"
      },
      "outputs": [],
      "source": [
        "# üìù ESPACIO PARA TUS EJERCICIOS\n",
        "# Usa esta celda para experimentar y desarrollar tus soluciones\n",
        "\n",
        "# Ejemplo: Funci√≥n para contar entidades por tipo\n",
        "def contar_entidades_por_tipo(texto):\n",
        "    \"\"\"Cuenta entidades por categor√≠a usando Transformers\"\"\"\n",
        "    if not ner_pipeline:\n",
        "        return {}\n",
        "\n",
        "    entidades = ner_pipeline(texto)\n",
        "    conteo = {}\n",
        "\n",
        "    for ent in entidades:\n",
        "        tipo = ent['entity_group']\n",
        "        if tipo in conteo:\n",
        "            conteo[tipo] += 1\n",
        "        else:\n",
        "            conteo[tipo] = 1\n",
        "\n",
        "    return conteo\n",
        "\n",
        "# Probar la funci√≥n\n",
        "texto_prueba = \"Juan P√©rez trabaja en Google Argentina en Buenos Aires con Mar√≠a L√≥pez.\"\n",
        "print(\"üìä Conteo de entidades:\")\n",
        "print(contar_entidades_por_tipo(texto_prueba))\n",
        "\n",
        "# TODO: Agrega aqu√≠ tus propias funciones y experimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_section"
      },
      "source": [
        "---\n",
        "# üéØ Conclusi√≥n\n",
        "\n",
        "¬°Felicitaciones! Completaste el ejercicio de Reconocimiento de Entidades Nombradas.\n",
        "\n",
        "## üìö Lo que aprendiste:\n",
        "- ‚úÖ Implementar NER con modelos pre-entrenados\n",
        "- ‚úÖ Usar APIs de IA generativa para tareas de PLN\n",
        "- ‚úÖ Crear interfaces interactivas con Gradio\n",
        "- ‚úÖ Comparar diferentes enfoques de NER\n",
        "\n",
        "## üîÑ Pr√≥ximos pasos:\n",
        "1. Experiment√° con otros modelos de Hugging Face\n",
        "2. Prob√° con textos de diferentes dominios\n",
        "3. Implementa tu proyecto integrador\n",
        "4. Compart√≠ tus resultados con la clase\n",
        "\n",
        "## üìñ Recursos adicionales:\n",
        "- [Hugging Face Models](https://huggingface.co/models?pipeline_tag=token-classification&language=es)\n",
        "- [Gradio Documentation](https://gradio.app/docs/)\n",
        "- [Google AI Studio](https://ai.google.dev/)\n",
        "\n",
        "---\n",
        "**¬°√âxito en tu trabajo integrador!** üéìüöÄ"
      ]
    }
  ]
}